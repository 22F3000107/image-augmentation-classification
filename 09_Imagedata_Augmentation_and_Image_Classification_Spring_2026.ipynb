{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "intro-header"
      },
      "source": [
        "<div align=\"left\" style=\"background-color: #008080; padding: 20px 10px;\">\n",
        "<h3><b>IDEAS - Institute of Data Engineering, Analytics and Science Foundation</b></h3>\n",
        "<p>Spring Internship Program 2026</p>\n",
        "<hr style=\"width:100%;\">\n",
        "<h3><b>Project Title:</b> Imagedata Augmentation and Image Classification</h3>\n",
        "<h4>Project Notebook</h4>\n",
        "\n",
        "<blockquote style=\"border-left: 4px solid #4285F4; padding-left: 15px;\">\n",
        "  <strong>Created by:</strong> Koustab Ghosh<sup>1</sup> & Sujoy Kumar Biswas<sup>2</sup><br>\n",
        "  <strong>Designation:</strong>\n",
        "  <ol style=\"margin-top: 5px; padding-left: 20px; font-size: 0.9em;\">\n",
        "    <li>Researcher, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "    <li>Head of Research & Innovation, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "  </ol>\n",
        "</blockquote>\n",
        "<hr style=\"width:100%;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q1-markdown"
      },
      "source": [
        "### Question 1: Import Libraries and Load Image (5 Marks)\n",
        "\n",
        "Import `numpy` as `np` and `cv2`. Download the image 'moon-pexels-frank-cone.jpg' from https://drive.google.com/drive/folders/1TeLp4U4NsXCSgClbF7ODBsaLKpHSWeQr?usp=sharing and load it into a variable named `original_image` using OpenCV. Print the shape of the loaded image.\n",
        "\n",
        "**Hint:** Use `cv2.imread()` to load the image and `.shape` to get its dimensions.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the image (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_MVUMTv9dSB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e18cbe0-8a35-44e5-d584-53b4081d6fac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q1-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2bcfc3-8306-4726-8bc5-a85b4b3e340b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/MyDrive/IDEAS_Spring_Internship_2026/moon-pexels-frank-cone.jpg\"\n",
        "original_image = cv2.imread(image_path)\n",
        "\n",
        "print(original_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q2-markdown"
      },
      "source": [
        "### Question 2: Convert to Grayscale (5 Marks)\n",
        "\n",
        "Convert the `original_image` to grayscale using OpenCV's `cvtColor` function. Store the result in a variable named `grayscale_image`. Print the shape of the new grayscale image.\n",
        "\n",
        "**Hint:** Use `cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)`. The shape of the grayscale image will have two dimensions instead of three.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the grayscale image (height, width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q2-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ec76a8-21f7-4fc4-a4c5-a022d6f04596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640)\n"
          ]
        }
      ],
      "source": [
        "grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "print(grayscale_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q3-markdown"
      },
      "source": [
        "### Question 3: Save the Grayscale Image (5 Marks)\n",
        "\n",
        "Save your `grayscale_image` to a file named `graymoon.jpg`.\n",
        "\n",
        "**Hint:** Use the `cv2.imwrite('filename.jpg', image_variable)` function.\n",
        "\n",
        "**Expected Output:** No direct output, but a file named `graymoon.jpg` will be created in your workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q3-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d6f052-61ab-405a-e9fe-3a68ed3f2319"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "cv2.imwrite(\n",
        "    \"/content/drive/MyDrive/MyDrive/IDEAS_Spring_Internship_2026/graymoon.jpg\",\n",
        "    grayscale_image\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q4-markdown"
      },
      "source": [
        "### Question 4: Shift the Image (10 Marks)\n",
        "\n",
        "Create a transformation matrix `M` to shift the `original_image` 50 pixels to the right and 100 pixels down. Apply this transformation using `cv2.warpAffine` and store the result in `shifted_image`. Print the shape of `shifted_image`.\n",
        "\n",
        "**Hint:** The matrix `M` will be a 2x3 NumPy float32 array: `np.float32([[1, 0, 50], [0, 1, 100]])`. The output shape should be the same as the original image.\n",
        "\n",
        "**Expected Output:** The shape of the shifted image, which will be identical to the original image's shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q4-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fee2ad-7f17-416a-b2e2-ac8df4cea1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Get image dimensions\n",
        "h, w = original_image.shape[:2]\n",
        "\n",
        "# Transformation matrix: shift 50 pixels right and 100 pixels down\n",
        "M = np.float32([\n",
        "    [1, 0, 50],\n",
        "    [0, 1, 100]\n",
        "])\n",
        "\n",
        "# Apply the affine transformation\n",
        "shifted_image = cv2.warpAffine(original_image, M, (w, h))\n",
        "\n",
        "print(shifted_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q5-markdown"
      },
      "source": [
        "### Question 5: Resize the Image (10 Marks)\n",
        "\n",
        "Resize the `original_image` to be 150 pixels wide and 100 pixels tall. Store the result in a variable named `resized_image` and print its new shape.\n",
        "\n",
        "**Hint:** Use the `cv2.resize()` function. The desired size is passed as a tuple `(width, height)`.\n",
        "\n",
        "**Expected Output:** The tuple `(100, 150, 3)` representing the new shape (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q5-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3395df5-74c5-44ce-97b7-b667936c398f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 150, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Resize the image to width = 150 pixels and height = 100 pixels\n",
        "resized_image = cv2.resize(original_image, (150, 100))\n",
        "\n",
        "# Print the new shape\n",
        "print(resized_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q6-markdown"
      },
      "source": [
        "### Question 6: Rotate the Image (10 Marks)\n",
        "\n",
        "Rotate the `original_image` by 90 degrees counter-clockwise around its center. Store the result in a variable named `rotated_image` and print its shape.\n",
        "\n",
        "**Hint:** First, get the image dimensions. Then, create a rotation matrix using `cv2.getRotationMatrix2D(center, angle, scale)`. Finally, apply it with `cv2.warpAffine`.\n",
        "\n",
        "**Expected Output:** The shape of the rotated image. Note that the height and width will be swapped compared to the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q6-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766235df-175c-4469-b0d6-633f37e073de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 800, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Get image dimensions\n",
        "h, w = original_image.shape[:2]\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "# Rotation matrix for 90 degrees counter-clockwise\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
        "\n",
        "# Apply rotation\n",
        "rotated_image = cv2.warpAffine(original_image, rotation_matrix, (h, w))\n",
        "\n",
        "print(rotated_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q7-markdown"
      },
      "source": [
        "### Question 7: Download and Unzip Cat/Dog Data (10 Marks)\n",
        "\n",
        "Download the Cat and Dog image dataset from the following link https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip and then unzip it. This will create a 'Cat_Dog_data' directory.\n",
        "\n",
        "**Hint:** Download and unzip to extract the files.\n",
        "\n",
        "**Expected Output:** No direct Python output, but the cell's log should show the download and extraction process completing successfully."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/MyDrive/IDEAS_Spring_Internship_2026/Cat_Dog_data.zip\"\n",
        "extract_path = \"/content/drive/MyDrive/MyDrive/IDEAS_Spring_Internship_2026/\"\n",
        "dataset_folder = os.path.join(extract_path, \"Cat_Dog_data\")\n",
        "\n",
        "# Extract only if not already extracted\n",
        "if not os.path.exists(dataset_folder):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "jhAl3EuBXYHH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q8-markdown"
      },
      "source": [
        "### Question 8: Create an Image Transform Pipeline (15 Marks)\n",
        "\n",
        "Import `torch` and necessary modules from `torchvision`. Define a transform pipeline named `train_transform` that resizes images to 255x255, randomly flips them horizontally, and then converts them to a tensor.\n",
        "\n",
        "**Hint:** Use `transforms.Compose()` with a list containing `transforms.Resize()`, `transforms.RandomHorizontalFlip()`, and `transforms.ToTensor()`.\n",
        "\n",
        "**Expected Output:** No output, but the `train_transform` object should be created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q8-code"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((255, 255)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q9-markdown"
      },
      "source": [
        "### Question 9: Create an ImageFolder Dataset (15 Marks)\n",
        "\n",
        "Create an `ImageFolder` dataset named `train_dataset` from the `'Cat_Dog_data/train'` directory, applying the `train_transform` pipeline you just created. Print the total number of images found in the dataset.\n",
        "\n",
        "**Hint:** Use `datasets.ImageFolder(data_dir, transform=your_transform)`. The number of images is the length of the dataset object, which you can get with `len()`.\n",
        "\n",
        "**Expected Output:** A printout of the number of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q9-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ddd6d4-f2be-4fc5-e400-989ff09ec374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22500\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/MyDrive/IDEAS_Spring_Internship_2026/Cat_Dog_data/train\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
        "\n",
        "print(len(train_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q10-markdown"
      },
      "source": [
        "### Question 10: Create a DataLoader (15 Marks)\n",
        "\n",
        "Create a `DataLoader` named `train_loader` from the `train_dataset`. Set the `batch_size` to 64 and `shuffle` to True. Then, retrieve one batch of images and labels from the loader and print the shape of the images tensor and the labels tensor.\n",
        "\n",
        "**Hint:** Use `torch.utils.data.DataLoader()`. To get one batch, use `images, labels = next(iter(train_loader))`. Print `images.shape` and `labels.shape`.\n",
        "\n",
        "**Expected Output:** Two printed tuples representing the shapes of the image batch and the label batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q10-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36db54d9-d706-4c0f-9356-acaec00e7a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 255, 255])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}